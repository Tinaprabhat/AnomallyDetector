# -------------------------
# ðŸš« Suppress sklearn warnings for cleaner logs
# -------------------------
import warnings
from sklearn.exceptions import UndefinedMetricWarning
warnings.filterwarnings("ignore", category=UndefinedMetricWarning)

from Source.dataset import EllipticDataset

if __name__ == "__main__":
    ds = EllipticDataset(root="Data/elliptic_bitcoin_dataset")
    G = ds.load()
    print(f"Graph Loaded: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges")

from Source.preprocessing import preprocess_features

X_scaled = preprocess_features(ds.features)
print("Preprocessed Feature Matrix:", X_scaled.shape)

from Source.baselines import run_baselines

results = run_baselines(X_scaled)
for model, preds in results.items():
    print(model, "unique predictions:", set(preds))

import numpy as np

for name, preds in results.items():
    np.save(f"outputs/{name}_preds.npy", preds)

from Source.trainer_gnn import run_gnn_phase2

# This function should encapsulate Phase 2: returns embeddings and model
embeddings, gnn_model, data, valid_nodes = run_gnn_phase2(ds, "outputs")
print("embeddings.shape:", embeddings.shape)
try:
    print("len(valid_nodes):", len(valid_nodes))
except NameError:
    print("valid_nodes not returned by run_gnn_phase2")
# If data exists, try to inspect node_ids if available
if 'data' in locals():
    print("Has attribute node_ids in data?", hasattr(data, 'node_ids'))
    if hasattr(data, 'node_ids'):
        print("len(data.node_ids):", len(data.node_ids))


print(f"[INFO] GNN embeddings shape: {embeddings.shape}")
  # ------------------------------------
# âœ… Robust Label-Embedding Alignment
# ------------------------------------
import pandas as pd
import numpy as np
import os

# Convert everything to strings to avoid type mismatch
data_node_ids = pd.Index(data.node_ids).astype(str)

# Load and map labels
labels_df = ds.classes.set_index("txId")["label"].astype(str)
label_map = {"1": "0", "2": "1", "licit": "0", "illicit": "1"}
labels_df = labels_df.replace(label_map)

# Keep only nodes present in GNN subgraph
labels_filtered = labels_df.loc[labels_df.index.intersection(data_node_ids)]

# Remove unlabeled (-1) rows if any
valid_mask = labels_filtered != "-1"

# Align order with data.node_ids
labels_aligned = labels_filtered.loc[data_node_ids]
valid_mask = valid_mask.loc[data_node_ids]

# Now safely index embeddings
embeddings_final = embeddings[valid_mask.values]
labels_final = labels_aligned[valid_mask].astype(int).values

# Build node_ids Series properly (avoid 'txId' KeyError)
node_ids_final = pd.Series(data_node_ids[valid_mask.values], name="txId")

print("[DEBUG] embeddings_final:", embeddings_final.shape)
print("[DEBUG] labels_final:", labels_final.shape)
print("[DEBUG] node_ids_final length:", len(node_ids_final))
print(np.all(valid_mask.index == pd.Index(data.node_ids).astype(str)))

from Source.anomaly_detector import run_anomaly_detection
# -------------------------
# Phase 3: Anomaly Detection
# -------------------------

anomaly_results = run_anomaly_detection(
    embeddings_final,
    labels_df=ds.classes,  
    node_ids=node_ids_final,
    save_path="outputs",
    contamination=0.05
)

print("[INFO] Anomaly detection completed successfully.")
# -------------------------
# âœ… Phase 4: Evaluation
# -------------------------
from Evaluation.evaluation import evaluate_anomaly_detection
import torch
import numpy as np
import pandas as pd

print("\n[INFO] Starting Phase 4: Evaluation...")

# âœ… Ensure anomaly_results is 1D numpy array of scores
if isinstance(anomaly_results, pd.DataFrame):
    # If it already has a score column
    if "anomaly_score" in anomaly_results.columns:
        anomaly_scores = anomaly_results["anomaly_score"].values
    else:
        anomaly_scores = anomaly_results.values.flatten()
elif isinstance(anomaly_results, np.ndarray):
    anomaly_scores = anomaly_results.flatten()
else:
    anomaly_scores = np.array(anomaly_results).flatten()

print(f"[DEBUG] anomaly_scores shape: {anomaly_scores.shape}")

# âœ… Create txIds (if available from data)
try:
    tx_ids = np.array(data.node_ids)[:len(anomaly_scores)]
except Exception:
    tx_ids = np.arange(len(anomaly_scores))  # fallback if node_ids missing

# âœ… Build the anomaly_results DataFrame correctly
anomaly_results = pd.DataFrame({
    "txId": tx_ids,
    "anomaly_score": anomaly_scores
})

print("[INFO] anomaly_results DataFrame created successfully.")
print(anomaly_results.head())

# âœ… Ensure labels are in DataFrame format
if isinstance(labels_aligned, (np.ndarray, list)):
    labels_df = pd.DataFrame({
        "txId": np.arange(len(labels_aligned)),
        "label": labels_aligned
    })
else:
    labels_df = labels_aligned

# âœ… Run Evaluation
print("[INFO] Running Evaluation Metrics...")
evaluate_anomaly_detection(anomaly_results, labels_df,embeddings)

print("[INFO] Phase 4 Evaluation completed successfully.")

# -------------------------
# âœ… Phase 5: Visualization
# -------------------------
from Visualization.visualize_results import visualize_anomaly_results

print("\n[INFO] Starting Phase 5: Visualization...")

visualize_anomaly_results(
    anomaly_results=anomaly_results,
    labels_df=labels_df,
    embeddings=embeddings,
    save_path="visualizations"
)

print("[INFO] Phase 5 completed successfully. Check 'visualizations/' for plots.")
# -------------------------
# âœ… Phase 6: Hyperparameter Optimization
# -------------------------
print("\n[INFO] Starting Phase 6: Hyperparameter Optimization...")

print(type(labels_df))
print(labels_df.head())


from Optimization.hyperparameter_tuning import optimize_hyperparameters

import pandas as pd

# ðŸ§  Ensure labels are a Series of numeric labels
if isinstance(labels_df, pd.DataFrame):
    if 'label' in labels_df.columns:
        labels_series = labels_df['label']
    elif 'Label' in labels_df.columns:
        labels_series = labels_df['Label']
    else:
        # Use the last column if label name unknown
        labels_series = labels_df.iloc[:, -1]
elif isinstance(labels_df, pd.Series):
    labels_series = labels_df
else:
    raise TypeError(f"Unexpected type for labels_df: {type(labels_df)}")

# ðŸ§© Run hyperparameter optimization
best_model, best_params, study = optimize_hyperparameters(
    embeddings,
    labels_series,
    n_trials=40
)

print("\n[INFO] Phase 6 Completed Successfully!")
print("[INFO] Best Parameters Found:")
print(best_params)



# -------------------------
# âœ… Phase 6: Reporting
# -------------------------
from Reporting.final_report import generate_final_report

print("\n[INFO] Starting Phase 6: Reporting...")

# Example: pass metrics from evaluation phase
metrics_dict = {
    "AUC": 0.8231,
    "Accuracy": 0.9456,
    "Precision": 0.9123,
    "Recall": 0.8674,
    "F1-Score": 0.8895
}

generate_final_report(metrics_dict)

print("[INFO] Phase 7 completed successfully.")
print("[INFO] Full project pipeline executed successfully ")




